# Performance

## Core Levers

- compile once, run many times.
- keep dataset scoped to required symbol/timeframe combinations.
- prefer canonical source naming to reduce resolver ambiguity.
- use planner/evaluator path for repeated expression execution.

## Typical Hotspots

- large fan-out over many symbol/timeframe keys,
- repeated graph rebuilds for identical expressions,
- expensive indicators on very long windows,
- heavy multi-source merge logic at ingestion boundary.

## Practical Optimization Steps

1. Cache compiled expressions by expression hash.
2. Cache plans and alignment policy decisions.
3. Pre-trim datasets using lookback requirements.
4. Use profiling around evaluator node-order execution when scaling to many symbols.

## Incremental Runtime Notes

- Incremental stepping and replay are Rust-backed.
- Keep Python-to-Rust crossings coarse-grained (`initialize/step/snapshot/replay`), not per-node.
- Treat replay determinism checks as required quality gates, not optional benchmarks.
