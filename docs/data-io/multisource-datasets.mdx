# Multi-Source Datasets

`dataset_from_multisource(...)` creates a single `Dataset` from normalized bars + trades + orderbook + liquidation payloads.

## Example

```python
from laakhay.ta.data.dataset import dataset_from_multisource

ds = dataset_from_multisource(
    symbol="BTCUSDT",
    timeframe="1h",
    bars=bars_payload,
    trades=trades_payload,
    orderbooks=orderbook_payload,
    liquidations=liquidation_payload,
    exchange="binance",
)
```

## Expected Input Shape

- `bars`: `timestamp, open, high, low, close, volume, is_closed?`
- `trades`: aggregate fields like `volume`, `count`, `buy_volume`, `sell_volume`, `avg_price`, `vwap`
- `orderbooks`: `best_bid`, `best_ask`, `spread`, `imbalance`, `pressure`, etc.
- `liquidations`: `count`, `value`, `long_count`, `short_count`, etc.

## Source Naming Behavior

When `exchange` is supplied, source keys are exchange-qualified where applicable (for example `trades_binance`), and additional field-level sources are stored for resolver flexibility.

## Practical Advice

- Keep all payloads on the same timeframe before constructing dataset.
- Validate timestamps and missing fields upstream.
- Use `analyze(...)` to verify required sources/fields before runtime execution.
